# CNTR AISLE Framework V1: **Questions**

The following are the questions of the Center for Technological Responsibility's AI Legislation Evaluation Framework V1 (**CNTR AISLE Framework**).

This is part of the **AI Legislative Mapping** project at the CNTR at Brown University.

Please contact us or raise an issue at <https://github.com/brown-cntr/cntr-aisle/> if you have questions or suggestions.

**Version**: *CNTR-AISLE-V1*

**Updated**: March 12, 2025

## GENERAL (G)



### Definition

[**G1**] Does the bill have a definition for "artificial intelligence" or "automated decision making / systems"?

[**G1a**] If "Yes" to G1, please select at least one of the following categories of AI definitions that is closest to the definition of AI in the bill. 

Select "N/A" if there is no AI definition or the AI definition does not fit the following categories.

Feel free to use "Notes" to elaborate on your selection(s)

- *OECD: An AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.*
- *2019 NDAA: (1) Any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. (2) An artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action. (3) An artificial system designed to think or act like a human, including cognitive architectures and neural networks. (4) A set of techniques, including machine learning, that is designed to approximate a cognitive task. (5) An artificial system designed to act rationally, including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicating, decision making, and acting.*
- *2020 NDAA: The term ‘‘artificial intelligence’’ means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. Artificial intelligence systems use machine and human-based inputs to— (A) perceive real and virtual environments; (B) abstract such perceptions into models through analysis in an automated manner; and (C) use model inference to formulate options for information or action.*
- *EU AI Act: "AI system" means a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments;*
- *EU AI Act: "General-purpose AI model" means an AI model, including where such an AI model is trained with a large amount of data using self-supervision at scale, that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications, except AI models that are used for research, development or prototyping activities before they are placed on the market;*
- *N/A*

[**G1b**] If "Yes" to G1, please please select at least one of the following categories of ADS definitions that is closest to the definition of ADS in the bill. 

Select "N/A" if there is no ADS definition or the ADS definition does not fit the following categories.

Feel free to use "Notes" to elaborate on your selection(s)

- *General v1: "Automated decision system" means a computational process, including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques, that makes a decision, or facilitates human decision making  [usually followed by potential impacted entities]... [Example sources: US S-2134 (117th); SC S-404 (2023-2024)]*
- *General v2: "Automated decision system" means any computer program, method, statistical model, or process that aims to aid or replace human decision-making using algorithms or artificial intelligence. [Example source: RI SB-146 (2023)]*
- *Definition with "threshold" on decision: “Automated decision tool” means a system or service that uses artificial intelligence and has been specifically developed and marketed to, or specifically modified to, make, or be a controlling factor in making, consequential decisions. [Example source: CA AB-331 (2023-2024)]*
- *Government purpose v1: The term "automated decision system" means a system, software, or process that (i) uses computation, in whole or in part, to determine outcomes, make or aid decisions (including through evaluations, metrics, or scoring), inform policy implementation, collect data or observations, or otherwise interact with individuals or communities, including such a system, software, or process derived from machine learning, statistics, or other data processing or artificial intelligence techniques; and (ii) is not passive computing infrastructure. [Example source: US S-262 (118th)]*
- *Government purpose v2: "Automated decision system" means any machine-based system or application, including, but not limited to, any such system or application that is derived from machine learning, statistics, or other data processing or artificial intelligence techniques, which system is developed, procured, or utilized to make, inform, or materially support a critical decision made by a State agency. "Automated decision system" does not include passive computing infrastructure. [Example source: NJ S-1438 (221st)]*
- *Government purpose v3: "Automated decision system" means an algorithm, including an algorithm incorporating machine learning or other artificial intelligence techniques, that uses data-based analytics to make or support governmental decisions, judgments, or conclusions. [Example source: ID H-568 (2024)]*
- *N/A*

[**G1bi**] If the bill has ADS definition, does the bill provide exclusions for ADS? 

Select "N/A" if the bill does not define ADS.

For example, from NY S-7543 (2023-2024)

"Automated decision-making system" shall not include any software used primarily for basic computerized processes, such as calculators, spell check tools, autocorrect functions, spreadsheets, electronic communications, or any tool that relates only to internal management affairs such as ordering office supplies or processing payments, and that do not materially affect the rights, liberties, safety or welfare of any human


- *Yes*
- *No*
- *N/A*



### Enforcement

[**G2**] Does the bill include enforcement mechanisms to ensure compliance with any rules for AI governance?

[**G2a**] If “Yes” to G2, does the bill specify the party responsible for enforcement?



### Scope

[**G3**] Does the bill apply to public-sector use of AI / ADS?

[**G4**] Does the bill apply to private-sector use of AI / ADS?

[**G5**] Does the bill provide an explicit list of domains where AI / ADS is used?



### GenAI

[**G6**] Does the bill define concepts related to generative AI, e.g "large language model", "frontier model", "foundational model", etc?

[**G6a**] If "Yes" to G6, does the bill specify scope (e.g. model size, compute power) specifically related to generative AI or foundational model?



## ACCOUNTABILITY & TRANSPARENCY (A)

*Note: In this category of Accountability & Transparency, “IA” will refer to Impact Assessment and “RA” to Risk Assessment throughout this scorecard. Both terms will be treated synonymously within this category.*

### Definitions and General Requirements

[**A1**] Does the bill provide definitions for "Impact Assessment" (IA), "Risk Assessment" (RA), or similar forms of evaluation? If other forms of evaluation are used, please indicate in the Notes.

[**A2**] Does the bill require covered entities (as defined in the bill) to conduct Impact/Risk Assessment (IA/RA) or similar evaluations?

[**A3**] Does the bill specify the requirements or methodologies for conducting an IA/RA?

[**A4**] Does the bill refer to established standards, such as frameworks from NIST, or published industry standards, specific to accountability?



### Stakeholder Engagement

[**A5**] Does the bill mandate involving stakeholders, including potentially affected communities, in the IA/RA process?

[**A6**] Does the bill provide compensation and civil recourse for those affected by harms?



### Enforcement actions

[**A7**] Does the bill specify enforcement mechanisms or penalties for failing to conduct IA/RA as required?

[**A8**] Are third-party vendors or partners required to comply with the IA/RA provisions in the bill?



### Risk Identification

[**A9**] Does the bill specify or otherwise acknowledge risks caused by poor data quality or algorithmic inaccuracy?

[**A10**] Does the bill specify or otherwise acknowledgeprivacy harms?

[**A11**] Does the bill specify or otherwise acknowledge risks to individual rights and freedoms, such as harms to dignity, autonomy, or exposure to unauthorized disclosure and identity theft?

[**A11a**] If "Yes" to any of A9 - A11, does the bill require the covered companies to identify the origin, nature, and severity of those risks?



### Risk Mitigation

[**A12**] Does the IA/RA establish procedures to assess, benchmark, and monitor identified AI risks and related impacts?

[**A13**] Does the IA/RA propose measures to address the risks?

[**A14**] Does the IA/RA include the option of deploying the system in its current state with increased testing and controls, or if necessary, decommissioning the system?

[**A15**] Is risk management an ongoing procedure, with testing and evaluation occurring over the entire lifecycle of an AI system, including the post-deployment period?



### Lifecycle of Impact Assessments

[**A16**] Does the bill specify the frequency of IA/RA?

[**A16a**] If "Yes" to A16, are IA/RAs required at regular intervals (e.g., annually, biannually)?

[**A17**] Does the bill require a pre-deployment IA/RA before the system is implemented?

[**A18**] Does the bill require a post-deployment IA/RA after the system has been implemented?

[**A19**] Does the bill require IA/RAs for all stages of the model's life cycle (e.g., development, deployment, monitoring)?

[**A20**] Does the bill require IA/RAs for all stages of the data life cycle?

[**A21**] Does the bill mandate ongoing monitoring and updating of the IA/RA as the system evolves?



### Documentation and Transparency

[**A22**] Does the bill require maintenance of IA/RA documentation?

[**A23**] Does the bill require documentation detailing how a model functions and its intended use cases?

[**A24**] Does the bill require a transparency report?

[**A25**] Does the bill identify the party responsible for completing the transparency requirement?

[**A26**] Does the bill require regular reporting to government agencies?

[**A27**] Does the bill require public reporting/publication?



### Auditing and Compliance

[**A28**] Does the bill aim to address these risks by requiring auditing from expert third parties?

[**A28a**] If the bill includes auditing requirements or you select "Yes" for A28, does the bill define how frequently auditing should occur (i.e., single point or regular intervals)?



### Precautionary Measures and Licensing

[**A29**] Does the bill deploy precautionary measures (e.g., licensing)?

[**A30**] Does the bill include bans on AI systems (for e.g that are viewed as creating a catastropic risk)?

[**A31**] Does the bill propose a licensing regime for any AI systems?

[**A32**] Does the bill consider conditional licensing?

[**A32a**] If "Yes" to A32a, is the conditional licensing imposed by a regulator rather than self-imposed by companies?



### Post-Market Measures

[**A33**] Does the bill deploy post-market measures, such as post-market monitoring and recalls?

[**A34**] Does the bill give regulators extensive inspection and information-forcing capabilities?

[**A35**] Does the bill require tools of resilience, e.g., kill switches, emergency training and protocols, and establishing thresholds at which a deployed system should be shut down?



## BIAS & DISCRIMINATION (B)



### Definition

[**B1**] Does the bill define "algorithmic discrimination" (or a similar term) to characterize unfair treatment toward specific groups? Refer to the Glossary / Definitions for possible list of synonyms

[**B2**] Does the bill explicitly include legally protected characteristics (e.g., race, gender, age, religion, disability) in its definition of discrimination or bias?



### Impact

[**B3**] Does the bill identify specific sectors or domains where the bias provisions are applied?



### Mitigation Practices

[**B4**] Does the bill require or suggest examination of data sources that would implicate biased outcomes?

[**B5**] Does the bill restrict the use of AI systems that exhibit potentially discriminatory outcomes?

[**B6**] Does the bill propose or endorse specific methods to reduce algorithmic discrimination?

[**B7**] Does the bill mandate ongoing monitoring and evaluation of AI systems for bias?



## DATA PROTECTION (D)



### Rights & Standards related to Privacy

[**D1**] 
Rights & Standards related to Privacy [[**D1**] Does the bill mention or imply a right to privacy concerning personal data or individual information?]

[**D2**] 
Rights & Standards related to Privacy [[**D2**] Does the bill refer to established standards such as ISO standards or NIST guidelines specific to data protection?]

[**D3**] 
Rights & Standards related to Privacy [[**D3**] Does the bill include provisions for the enforcement of these data protection standards?]

[**D4**] 
Rights & Standards related to Privacy [[**D4**] Does the bill establish a private right of action?]



### Data Sensitivity

[**D5**] Does the bill provide a definition of sensitive data?

[**D6**] Does the bill have specific requirements for handling sensitive data?

[**D7**] Does the bill require limits on access/use of sensitive data?

[**D8**] Does the bill require disclosure of the specific categories of sensitive data collected?



### Data Collection (Pre-Deployment)

[**D9**] Does the bill specify guidelines or limitations regarding data collection practices?

[**D10**] Does the bill specify the allowable time frame or conditions under which data can be collected during the pre-deployment stage?



### Data Minimization

[**D11**] Does the bill reference data minimization?

[**D12**] Does the bill require explicit, informed consent from individuals before collecting their personal data?

[**D13**] Does the bill establish oversight mechanisms to ensure compliance with consent requirements for data collection?

[**D14**] Does the bill require organizations to document the specific purposes for which personal data is collected?

[**D15**] Does the bill require documentation of used datasets, including data sources, consent records, and data preprocessing activities?



### Data Usage (Post-Deployment)

[**D16**] Does the bill specify how personal data can be used after deployment of the AI system?

[**D17**] Does the bill define the duration or conditions under which personal data can be used post-deployment?



### Data Retention

[**D18**] Does the bill reference data retention practices?

[**D19**] Does the bill identify a data retention period?



### Data Transfer and Sharing

[**D20**] Does the bill specify the conditions under which personal data can be transferred or shared between parties domestically?

[**D21**] Does the bill specify the conditions for cross-border transfer or sharing of personal data?



### Data Deletion

[**D22**] Does the bill reference data deletion?

[**D23**] Does the bill address how individuals can request deletion of their data?

[**D24**] Does the bill address how individuals can verify the removal of their data?



### Data Security

[**D25**] Does the bill reference data security?

[**D26**] Does the bill specify requirements for informing individuals of data breaches?



### Data Subject Rights

[**D27**] Does the bill require mechanisms for individuals to ascertain if their personal data has been used in AI training datasets?

[**D28**] Does the bill provide remedies for individuals if their personal data is disclosed in AI outputs without consent?



## INSTITUTION (I)



### Institutional Development

[**I1**] Does the bill mandate the establishment of a new entity?

[**I2**] Does the bill outline clear, measurable objectives for the new entity that must be achieved within defined timelines?



### Institutional Collaboration

[**I3**] Does the bill identify how the new entity will work with existing agencies?



### Institutional Activity

[**I4**] Does the bill mandate periodic reporting and specify subsequent regulatory actions contigent upon report findings or identified compliance issues?



## LABOR FORCE (L)



### Labor Force & Upskilling

[**L1**] Does the bill contain provisions aimed at expanding the workforce in the AI Economy? Examples of provisions may include grants, access initiatives, etc.

[**L2**] Does the bill specify resources to train the labor force for AI-related skills?



### Collaboration

[**L3**] Does the bill specify partners to collaborate with to research the impact of AI on the labor force?



### Displacement

[**L4**] Does the bill call for the analysis of challenges faced by workers affected by automation or AI implementation?

[**L5**] Does the bill call for the analysis of demographics that may be most vulnerable to AI displacement?

[**L6**] Does the bill propose recommendations to alleviate work displacement as a result of AI?

[**L7**] Does the bill propose compensation for workers who are being displaced, replaced or unemployed due to AI or automation?


